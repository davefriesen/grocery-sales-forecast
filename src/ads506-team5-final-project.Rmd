---
title: "Grocery Sales Forecast"
author:
  Christine Vu^[University of San Diego, cvu@sandiego.edu], Dave Friesen^[University of San Diego, dfriesen@sandiego.edu]
date: "12/12/2022"
geometry: "left=2cm,right=2cm,top=2cm,bottom=2cm"
output:
  html_document:
    css: "style.css"
  pdf_document: default
---

<style>
.main-container {
  max-width: 1024px;
}
</style>


```{r setup, echo = FALSE, message = FALSE}
# Load basic libraries
#library(tidyr)
library(dplyr)

# Load visualization libraries
library(ggplot2)
library(ggrepel)
library(plotly)
library(grDevices)

# Load EDA libraries
#library(readr)
#library(RTextTools)
#library(readxl)

# Load model and performance evaluation libraries
library(zoo)
library(forecast)

# Load utility libraries
library(lubridate)
library(latex2exp)

# Expand output width and minimize exp notation
options(width = 150)
options(scipen = 100)
options(digits = 1)

# Set style defaults
knitr::opts_chunk$set(class.source = "source")
knitr::opts_chunk$set(class.output = "output")
knitr::opts_chunk$set(fig.width = 10, fig.height = (10 * .45), fig.align = "center")
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NA)
```


```{r data_univariate, echo = FALSE}
# Note this function is generic and doesn't look for more intelligent "blank" values like "no record",
#   "not available", etc.
is_blank <- function(x) {
  classof_x <- class(x)
  result <-
    !(is.na(x) | is.nan(x)) &
    (((classof_x == "character") & (x == "")) |
     ((classof_x %in% c("integer", "numeric")) & (x == 0)))
  return(result)
}

# Function to format percentages (only when value exists)
format_percent <- function(x) {
  result <- formatC(x * 100, digits = 0, width = 5, format = "d", zero.print = FALSE)
  if (round(x, 0.5) != 0) result <- paste(result, "%", sep = "")
  return(result)  
}

# Function to not output NaNs from third-party functions in lapply() below
nan_replace_0 <- function(x) {
  if (is.na(x) | is.nan(x)) result <- 0 else result = x
  return(result)
}

# Function to check if a valid date across types
is_any_date <- function(x) {
  is <- (class(x) == "Date")
  if (!is & is.character(x)) {
    tryCatch({ is <- is.Date(as.Date(x)) }
      , error = function(e) { }
      , warning = function(e) { }
    )
  }
  return(is)
}

# Function to Generate a summary of base dataset
univariate <- function(df, df_name = deparse(substitute((df)))) {
  rowcount <- nrow(df)

  ua <- do.call(rbind, lapply(df, function(x) c(
    colnames(x),
    class(x),
    format_percent(sum(is.na(x) | is.nan(x)) / rowcount),
    format_percent(sum(is_blank(x)) / rowcount),
    formatC(length(unique(na.omit(x))),
            digits = 0, width = 9, format = "d", big.mark = "", zero.print = FALSE),
    formatC(0,
            digits = 0, width = 4, format = "f", big.mark = "", zero.print = FALSE),
    formatC(ifelse(is.numeric(x), min(na.omit(x)), 0),
            digits = ifelse(is.double(x), 1, 0), width = 9, format = "f", big.mark = "", zero.print = FALSE),
    formatC(ifelse(is.numeric(x), max(na.omit(x)), 0),
            digits = ifelse(is.double(x), 1, 0), width = 9, format = "f", big.mark = "", zero.print = FALSE),
    formatC(ifelse(is.double(x), mean(na.omit(x)), 0),
            digits = 1, width = 9, format = "f", big.mark = "", zero.print = FALSE),
    formatC(ifelse(is.numeric(x), median(na.omit(x)), 0),
            digits = ifelse(is.double(x), 1, 0), width = 9, format = "f", big.mark = "", zero.print = FALSE),
    format(ifelse(is.numeric(x),
           ifelse(na.omit(x) < (quantile(na.omit(x), 0.25) - (1.5 * IQR(na.omit(x)))), "Yes", "No"), ""),
           justify = "centre", width = 8, format = "s"),
    format(ifelse(is.numeric(x),
           ifelse(na.omit(x) > (quantile(na.omit(x), 0.75) - (1.5 * IQR(na.omit(x)))), "Yes", "No"), ""),
           justify = "centre", width = 8, format = "s"),
    formatC(ifelse(is.numeric(x), nan_replace_0(e1071::skewness(na.omit(x))), 0),
            digits = 1, width = 8, format = "f", zero.print = FALSE),
    "",
    formatC(0,
            digits = 0, width = 4, format = "f", big.mark = "", zero.print = FALSE))))

  colnames(ua) <- c(
    "Type",
    format("NA%", justify = "right", width = 6),
    format("Blank%", justify = "right", width = 6),
    format("Unique", justify = "right", width = 9),
    format("Freq", justify = "right", width = 4),
    format("Min", justify = "right", width = 9),
    format("Max", justify = "right", width = 9),
    format("Mean", justify = "right", width = 9),
    format("Median", justify = "right", width = 9),
    format("Outlier<", justify = "centre", width = 8),
    format(">Outlier", justify = "centre", width = 8),
    format("Skewness", justify = "right", width = 8),
    format("nZV", justify = "centre", width = 3),
    format("ACF1", justify = "right", width = 4))

  nzv_cols <- caret::nearZeroVar(df, freqCut = 19, uniqueCut = 10, saveMetrics = FALSE, names = FALSE)

  for (x in 1:ncol(df)) {
    col <- row.names(ua)[x]

    ua[x, 5] <- formatC(ifelse(is_any_date(df[[col]]),
                               as.integer(difftime(max(as.Date(df[[col]])), min(as.Date(df[[col]])), units = c("days"))) /
                               length(unique(df[[col]])), 0),
                        digits = 0, width = 4, format = "f", big.mark = "", zero.print = FALSE)

    ua[x, 13] <- format(ifelse(x %in% nzv_cols, "Y", "N"),
                        justify = "centre", width = 3, format = "s")

    tryCatch({
        acf <- forecast::Acf(df[col], lag.max = 1, type = "correlation", plot = FALSE, level = 95)[[1]][2]
      }
      , error = function(e) { acf <- 0 }
      , warning = function(e) { acf <- 0 }
      , finally = {
          ua[x, 14] <- formatC(nan_replace_0(acf), digits = 1, width = 4, format = "f", zero.print = FALSE)
      }
    )
  }

  row.names(ua) <- lapply(row.names(ua),
                          function(x) if (nchar(x) > 20) return(paste(substr(x, 1, 17), "...", sep = ""))
                          else return(x))

  { cat(
    "Summary Univariate Analysis for ", df_name, " (",
    formatC(rowcount, big.mark = ","), " observations)\n",
    sep = "")
    print(noquote(ua))
  }
}
```


### Get Data

Reference: [https://www.kaggle.com/competitions/store-sales-time-series-forecasting/data?select=transactions.csv]

```{r}
#dir <- "/Users/christinevu/Downloads/"
dir <- "../data/"

# Load dataset(s)
setwd(dir)
sales_df <- read.csv("train.csv", header = TRUE)
sales_test_df <- read.csv("test.csv", header = TRUE)
stores_df <- read.csv("stores.csv", header = TRUE)
oil_df <- read.csv("oil.csv", header = TRUE)
events_df <- read.csv("holidays_events.csv", header = TRUE)

# Data validation and understanding, including structure, content, and statistical characteristics covered below
```


### Explore & Visualize Series

###### Univariate Analysis and Preliminary Pre-Processing

```{r, class.output="output_small"}
# e.g., statistical characteristics (including distribution, skewness, outliers)
#   +[optionally] review sample observations
univariate(sales_df); head(sales_df, 3); #str(sales_df)
univariate(sales_test_df); head(sales_test_df, 3); #str(sales_test_df)
univariate(stores_df); head(stores_df, 3); #str(stores_df)
univariate(oil_df); head(oil_df, 3); #str(oil_df)
univariate(events_df); head(events_df, 3); #str(events_df)

# The following code was key for preliminary EDA, with individual results ultimately summarized
#   through the above univariate() calls

# Data summary statistics
#summary(sales_df)
#summary(sales_test_df)
#summary(stores_df)
#summary(oil_df)
#summary(events_df)

# Data types
#lapply(sales_df, class)
#lapply(sales_test_df, class)
#lapply(stores_df, class)
#lapply(oil_df, class)
#lapply(events_df, class)

# Row and column counts
#nrow(sales_df)
#row(sales_test_df)
#ncol(sales_df)
#ncol(sales_test_df)

# Missing values
#sum(is.na(sales_df))
#sum(is.na(sales_test_df))
#sum(is.na(stores_df))
#sum(is.na(oil_df))
#sum(is.na(events_df))
```

```{r}
# Convert string mm/dd/yyyy to Date values and confirm sort
sales_df <- (sales_df %>%
               mutate(date = as.Date(date, format = "%Y-%m-%d"),) %>%
               arrange(date))
```


###### Series Visualization - All Product Families

```{r}
# Aggregate base dataframe by date (i.e., sum all product lines) and initlally plot series at
#   provided time granularity
sales_agg_df <- as.data.frame(sales_df %>%
                                group_by(date) %>%
                                summarize(sales = sum(sales / 1000.0)))
plot(x = sales_agg_df$date, y = sales_agg_df$sales, type = "l",
     main = "Store Sales for All Product Families  |  Daily  |  All Dates",
     xlab = TeX(r"(\textbf{Date (daily \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
     las = 1, cex.axis = 0.7)
```

```{r}
# Aggregate base dataframe from daily to weekly for all product families
sales_wk_df <- as.data.frame(sales_df %>%
                               mutate(year = year(date), week = week(date)) %>%
                               group_by(year, week) %>%
                               summarize(sales = sum(sales / 1000.0)))

# Create overall time series
sales_begin_year <- head(sales_wk_df$year, 1)
sales_begin_week <- head(sales_wk_df$week, 1)
sales_end_year <- tail(sales_wk_df$year, 1)
sales_end_week <- tail(sales_wk_df$week, 1)
sales_ts <- ts(sales_wk_df$sales,
               start = c(sales_begin_year, sales_begin_week),
               end = c(sales_end_year, sales_end_week), freq = 52)

# Plot overall time series with trend line
plot(sales_ts, type = "l",
     main = "Store Sales for All Product Families  |  Weekly  |  All Dates",
     xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
     las = 1, cex.axis = 0.7)

sales_lm <- tslm(sales_ts ~ trend + I(trend^2))
lines(sales_lm$fitted, lwd = 2, lty = 1, col = "red")

legend("bottomright",
       legend = c("Trend Line"),
       col = c("red"),
       lwd = 2, lty = 1.2, cex = 0.8,
       box.lty = 0, bg = NULL, text.col = "red")
```

```{r}
# Proportion by family
fam_prop <- sales_df %>%
              group_by(family) %>%
              summarise(Mean_Sales = round(mean(sales, na.rm = TRUE), 2),
                        Median_Sales = round(median(sales, na.rm = TRUE), 2),
                        Maximum_Sales = max(sales),
                        IQR_Sales = IQR(sales),
                        Total_Sales = sum(sales))
head(fam_prop, 3)
```

```{r}
# Box plot: Mean of store sales by family
fam_plot <- ggplot(fam_prop) +
            geom_col(aes(x = family, y = Mean_Sales, fill = family)) +
            theme(axis.ticks.x = element_blank(),
                  axis.text.x = element_blank()) +
            labs(title = "Average Store Sales by Family",
                 x = "Family of Product",
                 y = "Average of Daily Sales",
                 legend = "Family of Product Sold",
                 bty = "l")
ggplotly(fam_plot)
```

```{r}
# Box plot: Total store sales by family
fam_plot2 <- ggplot(fam_prop) +
             geom_col(aes(x = family, y = Total_Sales, fill = family)) +
             theme(axis.ticks.x = element_blank(),
                   axis.text.x = element_blank()) +
             labs(title = "Total Store Sales by Family",
                  x = "Family of Product",
                  y = "Average of Daily Sales",
                  legend = "Family of Product Sold",
                  bty = "l")
ggplotly(fam_plot2)
```

```{r}
# Extract day, month, year, etc. from sales_df
sales_df$day <- sales_df$date %>% day()
sales_df$month <- sales_df$date %>% month()
sales_df$month_lab <- sales_df$date %>% month(label = TRUE)
sales_df$year <- sales_df$date %>% year()
sales_df$week <- sales_df$date %>% week()
sales_df$week_day <- sales_df$date %>%
  wday(week_start = getOption("lubridate.week.start", 1), label = TRUE)
```

```{r}
opar = par()
par(mfrow = c(1, 2))

# Plot overall time series w/log scale
plot(sales_ts, type = "l",
     main = "Store Sales  |  Weekly  |  Log Scale",
     xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
     las = 1, cex.axis = 0.7,
     log = "y")

# Plot zoomed time series with trend line
sales_zoom_ts <- window(sales_ts, start = c(sales_end_year, 1), end = c(sales_end_year, 13))
plot(sales_zoom_ts, type = "l",
     main = "Store Sales  |  Weekly  |  One Quarter",
     xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
     xaxt = "n",
     las = 1, cex = 0.7)

sales_zoom_lm <- tslm(sales_zoom_ts ~ trend + I(trend^2))
lines(sales_zoom_lm$fitted, lwd = 2, lty = 1, col = "red")

axis(1, at = as.numeric(time(sales_zoom_ts)), labels = seq(sales_zoom_ts))

legend("bottomright",
       legend = "Trend Line",
       col = "red",
       lwd = 2, lty = 1.2, cex = 0.8,
       box.lty = 0, bg = NULL, text.col = "red")

par(opar)
```

```{r}
# Proportion by sales
sales_prop <- sales_df %>%
                group_by(store_nbr) %>%
                summarise(Mean_Sales = mean(sales),
                          Median_Sales = median(sales),
                          Maximum_Sales = max(sales),
                          IQR_Sales = IQR(sales),
                          IQR_to_avg_sales = IQR(sales) / mean(sales),
                          Total_Sales = sum(sales))
head(sales_prop, 3)
```

```{r}
# Bar plot: Average of store sales by day of the week in January 2013
sales_plot <- sales_df %>%
                group_by(date) %>%
                  summarise(avg_sales = mean(sales), wday = week_day, .groups = "keep") %>%
                    filter(date <= '2013-01-31') %>% 
                      ggplot() +
                      geom_col(aes(x = date, y = avg_sales, fill = wday)) +
                      labs(title = "Average of Daily Store Sales in January 2013",
                           x = "Date",
                           y = "Average of Daily Sales",
                           fill = "Day of the Week",
                           bty = "l")
sales_plot
```

```{r}
# Bar plot: Average of store sales by day of the week
sales_plot1 <- sales_df %>%
                group_by(week_day) %>%
                  summarise(avg_sales = mean(sales)) %>% 
                    ggplot() +
                    geom_col(aes(x = week_day,
                                 y = avg_sales,
                                 fill = week_day)) +
                    labs(title = "Average of Daily Store Sales by Day of the Week",
                         x = "Day of the Week",
                         y = "Average of Daily Sales",
                         fill = "Day of the Week",
                         bty = "l")
sales_plot1
# Bar plot: Average of store sales by week
sales_plot2 <- sales_df %>%
                group_by(week) %>%
                  summarise(avg_sales = mean(sales)) %>% 
                    ggplot() +
                    geom_col(aes(x = week,
                                 y = avg_sales,
                                 fill = as.factor(week))) +
                    labs(title = "Average of Daily Store Sales by Week",
                         x = "Week",
                         y = "Average of Weekly Sales",
                         fill = "Week",
                         bty = "l")
sales_plot2
# Bar plot: Average of store sales by month of the year
sales_plot3 <- sales_df %>%
                group_by(month_lab) %>%
                  summarise(avg_sales = mean(sales)) %>% 
                    ggplot() +
                    geom_col(aes(x = month_lab,
                                 y = avg_sales,
                                 fill = month_lab)) +
                    labs(title = "Average of Daily Store Sales by Month of the Year",
                         x = "Month",
                         y = "Average of Monthly Sales",
                         fill = "Month",
                         bty = "l")
sales_plot3
# Bar plot: Average of store sales by year
sales_plot4 <- sales_df %>%
                group_by(year) %>%
                  summarise(avg_sales = mean(sales)) %>% 
                    ggplot() +
                    geom_col(aes(x = year,
                                 y = avg_sales,
                                 fill = as.factor(year))) +
                    labs(title = "Average of Daily Store Sales by Year",
                         x = "Year",
                         y = "Average of Yearly Sales",
                         fill = "Year",
                         bty = "l")
sales_plot4
```

```{r}
# Bar plot: Distribution of store types
store_plot <- stores_df$type %>%
                table() %>% 
                  as.data.frame() %>% 
                    ggplot() +
                    geom_col(aes(y = Freq, x = ., fill = as.factor(.))) +
                    labs(title = "Distribution of Store Types",
                         x = "Store Type",
                         fill = "Type",
                         bty = "l")
store_plot
```

```{r}
# Bar plot: Distribution of holiday type
events_plot1 <- events_df %>%
                  ggplot() +
                  geom_bar(aes(x = type, fill = type)) +
                  labs(title = "Distrbution of Type of Holiday",
                       x = "Type of Holiday",
                       fill = "Holiday Type",
                       bty = "l")
events_plot1
# Bar plot: Distribution of holiday locale
events_plot2 <- events_df %>%
                  ggplot() +
                  geom_bar(aes(x = locale, fill = locale)) +
                  labs(title = "Distribution of Holiday Locale",
                       x = "Holiday Locale",
                       fill = "Locale",
                       bty = "l")
events_plot2
```

```{r}
# Line chart: Daily oil price
oil_plot <- oil_df %>%
              ggplot(aes(x = date, y = dcoilwtico, color = dcoilwtico, group = 1)) +
              geom_line(na.rm = TRUE) +
              labs(title = "Daily Oil Price",
                   x = "Date",
                   y = "Oil Price",
                   color = "Oil Price",
                   bty = "l")
oil_plot
```


###### Series Visualization - Individual Product Families

```{r fig.height=3}
# Aggregate base dataframe from daily to weekly by product family
sales_wk_df <- as.data.frame(sales_df %>%
                               mutate(year = year(date), week = week(date)) %>%
                               group_by(family, year, week) %>%
                               summarize(sales = sum(sales / 1000.0)))

opar = par()
par(mfrow = c(1, 3))

for (f in unique(sales_wk_df$family)) {
  # Subset data by product family and create time series
  df <- filter(sales_wk_df, family == f)
  df_ts <- ts(df$sales,
              start = c(sales_begin_year, sales_begin_week),
              end = c(sales_end_year, sales_end_week), freq = 52)

  # Plot time series
  plot(df_ts, type = "l",
       main = paste("Store Sales for ", f, "  |  All Dates", sep = ""),
       height = 0.8,
       xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
       las = 1, cex.axis = 0.7)
}

par(opar)
```


### Pre-Process Data

```{r}
# Placeholder code to emove rows with NAs
#df %>%
#  na.omit()

# Placeholder code to remove rows with NAs in specific column
#df %>%
#  filter(!is.na(column_name))

# Placeholder code to reemove duplicates
#df %>%
#  distinct()

# Placeholder code to remove rows by index position
#df %>%
#  filter(!row_number() %in% c(1, 2, 4))

# Remove rows not considered "core"
keep_families <- c("BEAUTY", "BEVERAGES", "BREAD/BAKERY", "CLEANING", "DAIRY",
                   "DELI", "EGGS", "FROZEN FOODS", "GROCERY", "GROCERY II", "HARDWARE",
                   "LIQUOR,WINE,BEER", "MEATS", "PERSONAL CARE", "PET SUPPLIES", "POULTRY",
                   "PREPARED FOODS", "PRODUCE", "SEAFOOD")
remove_families <- c("AUTOMOTIVE", "BABY CARE", "BOOKS", "CELEBRATION", "HOME APPLIANCES",
                     "HOME AND KITCHEN I", "HOME AND KITCHEN II", "HOME CARE", "LADIESWEAR",
                     "LAWN AND GARDEN", "LINGERIE", "MAGAZINES", "PET SUPPLIES",
                     "PLAYERS AND ELECTRONICS", "SCHOOL AND OFFICE SUPPLIES")
sales_core_df <- (sales_df %>%
                    filter(family %in% keep_families))
```

```{r}
# Mean of missing oil_df data
mean(is.na(oil_df))
# Option: Drop missing records since they only account for 2% of data
# na.omit(oil_df)
# oil_df2: New 'oil_df' data frame without missing values
# Foward and backward fill for missing values
oil_df2 <- na.locf(oil_df, fromLast = TRUE)
# Confirm oil_df2 has no more missing values
sum(is.na(oil_df2))
```

```{r}
# Box plot: oil_df2
oil_outliers <- ggplot(oil_df2) +
                aes(x = "", y = dcoilwtico) +
                geom_boxplot(fill = "#56B4E9") +
                labs(title = "Oil Box Plot",
                     x = "",
                     y = "Oil Price",
                     bty = "l")
oil_outliers
```

```{r}
# Convert string mm/dd/yyyy to Date values and confirm sort
oil_df <- (oil_df %>%
             mutate(date = as.Date(date, format = "%Y-%m-%d"),) %>%
             arrange(date))

# Add oil prices to sales dataset for potential use as external predictor
sales_core_df <- left_join(sales_core_df, oil_df, by = c("date"))
```


###### Series Visualization - Select ("Core") Product Families

```{r}
# Re-aggregate base dataframe from daily to weekly for all product families
sales_wk_df <- as.data.frame(sales_core_df %>%
                               mutate(year = year(date), week = week(date)) %>%
                               group_by(year, week) %>%
                               summarize(sales = sum(sales / 1000.0), dcoilwtico = mean(dcoilwtico, na.rm = TRUE)))

# Re-create overall time series
sales_begin_year <- head(sales_wk_df$year, 1)
sales_begin_week <- head(sales_wk_df$week, 1)
sales_end_year <- tail(sales_wk_df$year, 1)
sales_end_week <- tail(sales_wk_df$week, 1)
sales_ts <- ts(sales_wk_df$sales,
               start = c(sales_begin_year, sales_begin_week),
               end = c(sales_end_year, sales_end_week), freq = 52)

# Plot overall time series with moving averages
plot(sales_ts, type = "l",
     main = "Store Sales for Select Product Families  |  Weekly  |  All Dates",
     xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
     las = 1, cex.axis = 0.7)

sales_l_ma <- rollmean(sales_ts, k = 4, align = "right")
sales_c_ma <- ma(sales_ts, order = 4)
lines(sales_l_ma, lwd = 2, lty = 2, col = "blue")
lines(sales_c_ma, lwd = 2, lty = 1, col = "red")

legend("bottomright",
       legend = c("Right Moving Average", "Centered Moving Average"),
       col = c("blue", "red"),
       lwd = 2, lty = c(2, 1), cex = 0.8,
       box.lty = 0, bg = NULL, text.col = c("blue", "red"))
```


### Partition Series

```{r}
# Use one year (52 weeks) as validation period (representative set of quarters, seasons)
sales_n_valid <- 52
sales_n_train <- length(sales_ts) - sales_n_valid

# Split data into training and validation periods
sales_train_ts <- window(sales_ts, start = c(sales_begin_year, 1), end = c(sales_begin_year, sales_n_train))
sales_valid_ts <- window(sales_ts, start = c(sales_begin_year, sales_n_train + 1), end = c(sales_begin_year, sales_n_train + sales_n_valid))

# Set x axis values based on ts ranges
x_train <- sales_begin_year
x_valid <- sales_begin_year + ((sales_n_train + 1) / 52)
x_future <- x_valid + ((sales_n_valid + 1) / 52)
```


### Apply Forecasting Method(s)

```{r}
# Initialize dataframe for tracking results across model approaches
results_df <- data.frame()
```


###### Naive Forecast Baseline

```{r}
# Fit seasonal naive model
sales_snaive_pred <- snaive(sales_train_ts, h = sales_n_valid)

# Summarize seasonal naive forecast results
accuracy(sales_snaive_pred, sales_valid_ts)
results_df <- rbind(results_df, data.frame(Model = "Naive (baseline)",
                                           Set = c("Train", "Test"),
                                           accuracy(sales_snaive_pred, sales_valid_ts)))

# Plot seasonal naive forecaster
ymax <- max(sales_ts) * 1.5
xmax <- x_future + 1

plot(sales_snaive_pred, type = "l",
     main = "Store Sales for Select Product Families  |  Seasonal Naive Forecaster",
     xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
     las = 1, cex.axis = 0.7,
     xlim = c(x_train, xmax), ylim = c(0, ymax))

# Add additional lines
lines(sales_valid_ts, lwd = 2, col = "red")

# Add plot defintions
lines(c(x_train, x_train), c(0, ymax), lwd = 3, lty = 3)
lines(c(x_valid, x_valid), c(0, ymax), lwd = 3, lty = 3)
lines(c(x_future, x_future), c(0, ymax), lwd = 3, lty = 3)

text(x_train + ((x_valid - x_train) * 0.5), ymax, "Training", font = 2, cex = 0.7)
text(x_valid + ((x_future - x_valid) * 0.5), ymax, "Validation", font = 2, cex = 0.7)
text(x_future + 0.5, ymax, "Future", font = 2, cex = 0.7)

legend("bottomright",
       legend = c("Forecast", "Actual"),
       col = c("dodgerblue", "red"),
       lwd = 2, lty = 1, cex = 0.8,
       box.lty = 0, bg = NULL, text.col = c("dodgerblue", "red"))
```


###### Data-Driven: Smoothing Methods

```{r}
# Fit Holt-Winter's model with (A)dditive error, (A)dditive trend, and (A)dditive seasonality
#   for last year of training series
sales_hw <- ets(window(sales_train_ts, start = c(sales_begin_year, sales_n_train + 1 - sales_n_valid),
                       end = c(sales_begin_year, sales_n_train + 1)),
                model = "AAA")

# Forecast (predict) for validation period
sales_hw_pred <- forecast(sales_hw, h = length(sales_valid_ts), level = 0)

# Summarize forecast (validation) performance
accuracy(sales_hw_pred, sales_valid_ts)
results_df <- rbind(results_df, data.frame(Model = "Holt-Winter's Smoothing",
                                           Set = c("Train", "Test"),
                                           accuracy(sales_hw_pred, sales_valid_ts)))

# Plot Holt-Winter's model
plot(sales_hw_pred, type = "l",
     main = "Store Sales for Select Product Families  |  Holt-Winter's Forecaster",
     xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
     las = 1, cex.axis = 0.7,
     xlim = c(x_train, xmax), ylim = c(0, ymax))

# Add additional lines
lines(sales_hw$fitted, lwd = 3, col = adjustcolor("dodgerblue", alpha.f = 0.3))
lines(sales_valid_ts, lwd = 2, col = "red")

# Add plot defintions
lines(c(x_train, x_train), c(0, ymax), lwd = 3, lty = 3)
lines(c(x_valid, x_valid), c(0, ymax), lwd = 3, lty = 3)
lines(c(x_future, x_future), c(0, ymax), lwd = 3, lty = 3)

text(x_train + ((x_valid - x_train) * 0.5), ymax, "Training", font = 2, cex = 0.7)
text(x_valid + ((x_future - x_valid) * 0.5), ymax, "Validation", font = 2, cex = 0.7)
text(x_future + 0.5, ymax, "Future", font = 2, cex = 0.7)

legend("bottomright",
       legend = c("Forecast", "Actual"),
       col = c("dodgerblue", "red"),
       lwd = 2, lty = 1, cex = 0.8,
       box.lty = 0, bg = NULL, text.col = c("dodgerblue", "red"))
```

```{r}
# Exponential smoothing models:
# ANN: (A)dditive error, (N)o trend, and (N)o seasonality
# AAN: (A)dditive error, (A)dditive trend, and (N)o seasonality
# MMN: (M)ultiplicative error, (M)ultiplicative trend, and (N)o seasonality
# MMdN: Multiplicative damped trend (Md)

sales.ets.ANN <- ets(sales_train_ts, model = "ANN")
sales.ets.AAN <- ets(sales_train_ts, model = "AAN")
sales.ets.MMN <- ets(sales_train_ts, model = "MMN", damped = FALSE)
sales.ets.MMdN <- ets(sales_train_ts, model = "MMN", damped = TRUE)

sales.ets.ANN.pred <- forecast(sales.ets.ANN)
sales.ets.AAN.pred <- forecast(sales.ets.AAN)
sales.ets.MMN.pred <- forecast(sales.ets.MMN)
sales.ets.MMdN.pred <- forecast(sales.ets.MMdN)

# Plot exponential smoothing models
plot(sales.ets.ANN.pred, main = "ANN Model", xlab = "Date", ylab = "Sales")
plot(sales.ets.AAN.pred, main = "AAN Model", xlab = "Date", ylab = "Sales")
plot(sales.ets.MMN.pred, main = "MMN Model", xlab = "Date", ylab = "Sales")
plot(sales.ets.MMdN.pred, main = "MMdN Model", xlab = "Date", ylab = "Sales")

# Summarize forecast (validation) performance
accuracy(sales.ets.ANN.pred, sales_valid_ts)
accuracy(sales.ets.AAN.pred, sales_valid_ts)
accuracy(sales.ets.MMN.pred, sales_valid_ts)
accuracy(sales.ets.MMdN.pred, sales_valid_ts)

results_df <- rbind(results_df, data.frame(Model = "Exponential Smoothing (AAN)",
                                           Set = c("Train", "Test"),
                                           accuracy(sales.ets.ANN.pred, sales_valid_ts)))
results_df <- rbind(results_df, data.frame(Model = "Exponential Smoothing (AAN)",
                                           Set = c("Train", "Test"),
                                           accuracy(sales.ets.AAN.pred, sales_valid_ts)))
results_df <- rbind(results_df, data.frame(Model = "Exponential Smoothing (MMN)",
                                           Set = c("Train", "Test"),
                                           accuracy(sales.ets.MMN.pred, sales_valid_ts)))
results_df <- rbind(results_df, data.frame(Model = "Exponential Smoothing (MMdN)",
                                           Set = c("Train", "Test"),
                                           accuracy(sales.ets.MMdN.pred, sales_valid_ts)))
```


###### Model-Based: Regression

```{r}
# Fit basic regression model with trend and seasonality
sales_lm <- tslm(sales_train_ts ~ trend + I(trend ^ 2) + season)

# Forecast (predict) for validation period
sales_lm_pred <- forecast(sales_lm, h = sales_n_valid, level = 0)

# Summarize performance metrics
accuracy(sales_lm_pred, sales_valid_ts)
results_df <- rbind(results_df, data.frame(Model = "Simple Regression",
                                           Set = c("Train", "Test"),
                                           accuracy(sales_lm_pred, sales_valid_ts)))

# Plot simple regression model
plot(sales_lm_pred, type = "l",
     main = "Store Sales for Select Product Families  |  Regression Forecaster",
     xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
     las = 1, cex.axis = 0.7,
     xlim = c(x_train, xmax), ylim = c(0, ymax))

# Add additional lines
lines(sales_lm$fitted, lwd = 3, col = adjustcolor("dodgerblue", alpha.f = 0.3))
lines(sales_valid_ts, lwd = 2, col = "red")

# Add plot defintions
lines(c(x_train, x_train), c(0, ymax), lwd = 3, lty = 3)
lines(c(x_valid, x_valid), c(0, ymax), lwd = 3, lty = 3)
lines(c(x_future, x_future), c(0, ymax), lwd = 3, lty = 3)

text(x_train + ((x_valid - x_train) * 0.5), ymax, "Training", font = 2, cex = 0.7)
text(x_valid + ((x_future - x_valid) * 0.5), ymax, "Validation", font = 2, cex = 0.7)
text(x_future + 0.5, ymax, "Future", font = 2, cex = 0.7)

legend("bottomright",
       legend = c("Forecast", "Actual"),
       col = c("dodgerblue", "red"),
       lwd = 2, lty = 1, cex = 0.8,
       box.lty = 0, bg = NULL, text.col = c("dodgerblue", "red"))
```


###### Model-Based: Regression w/Autocorrelation

```{r}
# Compute and plot autocorrelation
Acf(sales_train_ts, lag.max = 52, type = "correlation", plot = TRUE,
    main = "Store Sales for Select Product Families  |  Autocorrelation at Different Lags",
    xlab = TeX(r"(\textbf{Lag} )"), ylab = TeX(r"(\textbf{Autocorrelation} )"),
    xaxt = "n",
    level = 95)
```


###### Model-Based: Regression w/Autocorrelation - AR(1)

```{r}
# Compute and plot autocorrelation for regression residuals
Acf(sales_lm$residuals, lag.max = 52, type = "correlation", plot = TRUE,
    main = "Regression Residuals  |  Autocorrelation at Different Lags",
    xlab = TeX(r"(\textbf{Lag} )"), ylab = TeX(r"(\textbf{Autocorrelation} )"),
    xaxt = "n",
    level = 95)
```

```{r}
# Fit AR(1) second-layer model to regression residuals and forecast (predict) vs. validation;
#   use AR of 1, MA of 0, and integration (differencing) of 0
sales_res_arima <- Arima(sales_lm$residuals, order = c(1, 0, 2))
sales_res_pred <- forecast(sales_res_arima, h = sales_n_valid)

# Summarize forecast (validation) performance
accuracy(sales_res_pred, sales_valid_ts)
results_df <- rbind(results_df, data.frame(Model = "AR(1)",
                                           Set = c("Train", "Test"),
                                           accuracy(sales_res_pred, sales_valid_ts)))

rymin <- min(sales_res_pred$residuals)
rymax <- max(sales_res_pred$residuals) * 1.5

# Plot residuals
plot(sales_res_pred$residuals, type = "l",
     main = "Store Sales for Select Product Families  |  Residuals (errors) from AR(1)",
     xlab = TeX(r"(\textbf{Time (\textit{$t$})} )"), ylab = TeX(r"(\textbf{Residual (\textit{$y_t$})} )"),
     xaxt = "n",
     xlim = c(x_train, xmax), ylim = c(rymin, rymax))

# Add plot defintions
lines(c(x_train, x_train), c(rymin, rymax), lwd = 3, lty = 3)
lines(c(x_valid, x_valid), c(rymin, rymax), lwd = 3, lty = 3)
lines(c(x_future, x_future), c(rymin, rymax), lwd = 3, lty = 3)

text(x_train + ((x_valid - x_train) * 0.5), rymax, "Training", font = 2, cex = 0.7)
text(x_valid + ((x_future - x_valid) * 0.5), rymax, "Validation", font = 2, cex = 0.7)
text(x_future + 0.5, rymax, "Future", font = 2, cex = 0.7)

# Compute and plot autocorrelation for residual of residuals
Acf(sales_res_arima$residuals, lag.max = 52, type = "correlation", plot = TRUE,
    main = "AR(1) Residuals  |  Autocorrelation at Different Lags",
    xlab = TeX(r"(\textbf{Lag} )"), ylab = TeX(r"(\textbf{Autocorrelation} )"),
    xaxt = "n",
    level = 95)
```


###### Model-Based: Regression w/Autocorrelation - ARIMA

```{r}
# Fit ARIMA model
sales_arima <- Arima(sales_train_ts, order = c(1, 1, 0), seasonal = c(0, 1, 2))
sales_arima_pred <- forecast(sales_arima, h = length(sales_valid_ts))

# Summarize forecast (validation) performance
accuracy(sales_arima_pred, sales_valid_ts)
results_df <- rbind(results_df, data.frame(Model = "ARIMA",
                                           Set = c("Train", "Test"),
                                           accuracy(sales_arima_pred, sales_valid_ts)))

# Plot model
plot(sales_arima_pred, type = "l",
     main = "Store Sales for Select Product Families  |  ARIMA Forecaster",
     xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
     las = 1, cex.axis = 0.7,
     xlim = c(x_train, xmax), ylim = c(0, ymax))

# Add additional lines
lines(sales_arima$fitted, lwd = 3, col = adjustcolor("dodgerblue", alpha.f = 0.3))
lines(sales_valid_ts, lwd = 2, col = "red")

# Add plot defintions
lines(c(x_train, x_train), c(0, ymax), lwd = 3, lty = 3)
lines(c(x_valid, x_valid), c(0, ymax), lwd = 3, lty = 3)
lines(c(x_future, x_future), c(0, ymax), lwd = 3, lty = 3)

text(x_train + ((x_valid - x_train) * 0.5), ymax, "Training", font = 2, cex = 0.7)
text(x_valid + ((x_future - x_valid) * 0.5), ymax, "Validation", font = 2, cex = 0.7)
text(x_future + 0.5, ymax, "Future", font = 2, cex = 0.7)

legend("bottomright",
       legend = c("Forecast", "Actual"),
       col = c("dodgerblue", "red"),
       lwd = 2, lty = 1, cex = 0.8,
       box.lty = 0, bg = NULL, text.col = c("dodgerblue", "red"))
```


###### Model-Based: Regression w/Autocorrelation - ARIMA + External Predictor(r)

```{r}
# Setup train and validation
train_span <- sales_n_train / 52
valid_span <- sales_n_valid / 52
total_span <- train_span + valid_span
train_end <- ((sales_begin_year + trunc(train_span)) * 100) + ((train_span - floor(train_span)) * 52)
valid_end <- ((sales_begin_year + trunc(total_span)) * 100) + ((total_span - floor(total_span)) * 52)
sales_train_df <- as.data.frame(sales_wk_df %>%
                                  filter(((year * 100) + week) <= train_end))
sales_valid_df <- as.data.frame(sales_wk_df %>%
                                  filter(((year * 100) + week) > train_end))

# Identify outcome (target) - sales
sales_train_y <- ts(sales_train_df$sales, freq = 52)
sales_valid_y <- ts(sales_valid_df$sales, freq = 52)

# Identify external predictor(s) - oil price
sales_X <- c("dcoilwtico")
sales_train_X <- as.matrix(sales_train_df[ , sales_X])
sales_valid_X <- as.matrix(sales_valid_df[ , sales_X])

# Fit using auto.arima for sense of best component configuration, and summarize results both without and with external
#   predictor(s)
sales_aam <- auto.arima(sales_train_y)
sales_aamX <- auto.arima(sales_train_y, xreg = sales_train_X)
summary(sales_aam)
summary(sales_aamX)
```


###### Model-Based: Neural Network Autoregression

```{r}
#
set.seed(201)
nValid <- 36

# Fit Neural Network Autoregression model
sales_train.nnetar <- nnetar(sales_train_ts, repeats = 20, p = 10, P = 1, size = 7)
summary(sales_train.nnetar$model[[1]])
sales_train.nnetar.pred <- forecast(sales_train.nnetar, h = nValid)

# Plot model
plot(sales_train_ts, main = "Store Sales  |  Neural Network Autoregression",
     xlab = "Date", ylab = "Store Sales", xlim = c(2013, 2017),
     bty = "l", lty = 1)
axis(1, at = seq(2013, 2017, 1), labels = format(seq(2013, 2017, 1)))

# Add additional lines
lines(sales_train.nnetar.pred$fitted, lwd = 2, col = "blue")
lines(sales_train.nnetar.pred$mean, lwd = 2, col = "red", lty = 2)
lines(sales_valid_ts)

# Summarize performance
accuracy(sales_train.nnetar.pred, sales_valid_ts)
results_df <- rbind(results_df, data.frame(Model = "Neural Network Autoregression",
                                           Set = c("Train", "Test"),
                                           accuracy(sales_train.nnetar.pred, sales_valid_ts)))
```


### Evaluate & Compare Performance

```{r}
# Show table of summary results
print(results_df, row.names = FALSE)
```

```{r}
# Bar plot: RMSE of all models (Except AR(1))
results_df_reshape1 <- reshape2::melt(results_df, c("Model", "Set", "RMSE")) %>%
                        filter(Model != "AR(1)")
results_df_reshape1 %>%
  ggplot() +
  geom_bar(aes(x = reorder(Model, -RMSE), y = RMSE, fill = Set),
           stat = "identity",
           position = "dodge") +
  geom_text(data = results_df_reshape1 %>%
              group_by(Model, Set) %>%
              summarise(RMSE = max(RMSE),
                        label_RMSE = round(sum(RMSE, na.rm = TRUE), 1)),
            aes(x = Model, y = RMSE, label = label_RMSE),
            nudge_y = 30) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1)) +
  labs(title = "RMSE of All Models",
       x = "Model",
       y = "RMSE",
       bty = "l")
```

```{r}
# Bar plot: MAPE of all models (Except AR(1))
results_df_reshape2 <- reshape2::melt(results_df, c("Model", "Set", "MAPE")) %>%
                        filter(Model != "AR(1)")
results_df_reshape2 %>%
  ggplot() +
  geom_bar(aes(x = reorder(Model, -MAPE), y = MAPE, fill = Set),
           stat = "identity",
           position = "dodge") +
  geom_text(data = results_df_reshape2 %>%
              group_by(Model, Set) %>%
              summarise(MAPE = max(MAPE),
                        label_MAPE = round(sum(MAPE, na.rm = TRUE), 2)),
            aes(x = Model, y = MAPE, label = label_MAPE), nudge_y = 1) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1)) +
  labs(title = "MAPE of All Models",
       x = "Model",
       y = "MAPE",
       bty = "l")
```

```{r}
# Bar plot: RMSE of all models (Except AR(1))
results_df_reshape1 <- reshape2::melt(results_df, c("Model", "RMSE")) %>%
                        filter(Model != "AR(1)")
results_df_reshape1 %>%
  ggplot() +
  geom_bar(aes(x = reorder(Model, -RMSE), y = RMSE, fill = Model),
           stat = "identity",
           position = "dodge") +
  geom_text(data = results_df_reshape1 %>%
              group_by(Model) %>%
              summarise(RMSE = max(RMSE),
                        label_RMSE = round(sum(RMSE, na.rm = TRUE), 1)),
            aes(x = Model, y = RMSE, label = label_RMSE),
            nudge_y = 30) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1)) +
  labs(title = "RMSE of All Models",
       x = "Model",
       y = "RMSE",
       bty = "l")
```

```{r}
# Bar plot: MAPE of all models (Except AR(1))
results_df_reshape2 <- reshape2::melt(results_df, c("Model", "MAPE")) %>%
                        filter(Model != "AR(1)")
results_df_reshape2 %>%
  ggplot() +
  geom_bar(aes(x = reorder(Model, -MAPE), y = MAPE, fill = Model),
           stat = "identity",
           position = "dodge") +
  geom_text(data = results_df_reshape2 %>%
              group_by(Model) %>%
              summarise(MAPE = max(MAPE),
                        label_MAPE = round(sum(MAPE, na.rm = TRUE), 2)),
            aes(x = Model, y = MAPE, label = label_MAPE), nudge_y = 1) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1)) +
  labs(title = "MAPE of All Models",
       x = "Model",
       y = "MAPE",
       bty = "l")
```

```{r}
# Bar plot: Performance of all models
results_df_reshape = reshape2::melt(results_df, c("Model", "Set"))
ggplot(results_df_reshape) +
  geom_bar(aes(x = variable, y = value, fill = Model),
           stat = "identity",
           position = "dodge") +
  labs(title = "Performance of All Models",
       x = "Model",
       bty = "l")
```

