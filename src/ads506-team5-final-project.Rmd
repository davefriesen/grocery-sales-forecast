---
title: "Grocery Sales Forecast"
author:
  Christine Vu^[University of San Diego, cvu@sandiego.edu], Dave Friesen^[University of San Diego, dfriesen@sandiego.edu]
date: "12/12/2022"
geometry: "left=2cm,right=2cm,top=2cm,bottom=2cm"
output:
  html_document:
    css: "style.css"
  pdf_document: default
---

<style>
.main-container {
  max-width: 1024px;
}
</style>


### Define Goal


```{r setup, echo = FALSE, message = FALSE}
# Load R libraries
library(dplyr)
library(lubridate)
library(forecast)
library(latex2exp)

# Expand output width and minimize exp notation
options(width = 150)
options(scipen = 100)
options(digits = 1)

# Set style defaults
knitr::opts_chunk$set(class.source = "source")
knitr::opts_chunk$set(class.output = "output")
knitr::opts_chunk$set(fig.width = 10, fig.height = (10 * .45), fig.align = "center")
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NA)
```


```{r data_univariate, echo = FALSE}
# Load R libraries required by this function set
library(caret)  # nearZeroVar function
library(e1071)  # skewness function
library(forecast)  # time-series forecasting

# Note this function is generic and doesn't look for more intelligent "blank" values like "no record",
#   "not available", etc.
is_blank <- function(x) {
  classof_x <- class(x)
  result <-
    !(is.na(x) | is.nan(x)) &
    (((classof_x == "character") & (x == "")) |
     ((classof_x %in% c("integer", "numeric")) & (x == 0)))
  return(result)
}

# Function to format percentages (only when value exists)
format_percent <- function(x) {
  result <- formatC(x * 100, digits = 0, width = 5, format = "d", zero.print = FALSE)
  if (round(x, 0.5) != 0) result <- paste(result, "%", sep = "")
  return(result)  
}

# Function to not output NaNs from third-party functions in lapply() below
nan_replace_0 <- function(x) {
  if (is.na(x) | is.nan(x)) result <- 0 else result = x
  return(result)
}

# Function to Generate a summary of base dataset
univariate <- function(df, df_name = deparse(substitute((df)))) {
  rowcount <- nrow(df)

  ua <- do.call(rbind, lapply(df, function(x) c(
    colnames(x),
    class(x),
    format_percent(sum(is.na(x) | is.nan(x)) / rowcount),
    format_percent(sum(is_blank(x)) / rowcount),
    formatC(length(unique(na.omit(x))),
            digits = 0, width = 9, format = "d", big.mark = "", zero.print = FALSE),
    formatC(ifelse(is.numeric(x), min(na.omit(x)), 0),
            digits = ifelse(is.double(x), 1, 0), width = 9, format = "f", big.mark = "", zero.print = FALSE),
    formatC(ifelse(is.numeric(x), max(na.omit(x)), 0),
            digits = ifelse(is.double(x), 1, 0), width = 9, format = "f", big.mark = "", zero.print = FALSE),
    formatC(ifelse(is.double(x), mean(na.omit(x)), 0),
            digits = 1, width = 9, format = "f", big.mark = "", zero.print = FALSE),
    formatC(ifelse(is.numeric(x), median(na.omit(x)), 0),
            digits = ifelse(is.double(x), 1, 0), width = 9, format = "f", big.mark = "", zero.print = FALSE),
    format(ifelse(is.numeric(x),
           ifelse(na.omit(x) < (quantile(na.omit(x), 0.25) - (1.5 * IQR(na.omit(x)))), "Yes", "No"), ""),
           justify = "centre", width = 8, format = "s"),
    format(ifelse(is.numeric(x),
           ifelse(na.omit(x) > (quantile(na.omit(x), 0.75) - (1.5 * IQR(na.omit(x)))), "Yes", "No"), ""),
           justify = "centre", width = 8, format = "s"),
    formatC(ifelse(is.numeric(x), nan_replace_0(skewness(na.omit(x))), 0),
            digits = 1, width = 8, format = "f", zero.print = FALSE),
    "",
    0.0)))

  colnames(ua) <- c(
    "Type",
    format("NA%", justify = "right", width = 6),
    format("Blank%", justify = "right", width = 6),
    format("Unique", justify = "right", width = 9),
    format("Min", justify = "right", width = 9),
    format("Max", justify = "right", width = 9),
    format("Mean", justify = "right", width = 9),
    format("Median", justify = "right", width = 9),
    format("Outlier<", justify = "centre", width = 8),
    format(">Outlier", justify = "centre", width = 8),
    format("Skewness", justify = "right", width = 8),
    format("nZV", justify = "centre", width = 3),
    format("ACF1", justify = "right", width = 4))

  nzv_cols <- nearZeroVar(df, freqCut = 19, uniqueCut = 10, saveMetrics = FALSE, names = FALSE)

  for (x in 1:ncol(df)) {
    col <- row.names(ua)[x]
    ua[x, 12] <- format(ifelse(x %in% nzv_cols, "Y", "N"),
                        justify = "centre", width = 3, format = "s")

    tryCatch({
        acf <- Acf(df[col], lag.max = 1, type = "correlation", plot = FALSE, level = 95)[[1]][2]
      }
      , error = function(e) { acf <- 0 }
      , warning = function(e) { acf <- 0 }
      , finally = {
          ua[x, 13] <- formatC(nan_replace_0(acf), digits = 1, width = 4, format = "f", zero.print = FALSE)
      }
    )
  }

  row.names(ua) <- lapply(row.names(ua),
                          function(x) if (nchar(x) > 20) return(paste(substr(x, 1, 17), "...", sep = ""))
                          else return(x))

  { cat(
    "Summary Univariate Analysis for ", df_name, " (",
    formatC(rowcount, big.mark = ","), " observations)\n",
    sep = "")
    print(noquote(ua))
  }
}
```


### Get Data

```{r}
# Load dataset(s); assumes folder structure with data parallel to src
sales_df <- read.csv("../data/train.csv", header = TRUE)
sales_test_df <- read.csv("../data/test.csv", header = TRUE)
stores_df <- read.csv("../data/stores.csv", header = TRUE)
oil_df <- read.csv("../data/oil.csv", header = TRUE)
events_df <- read.csv("../data/holidays_events.csv", header = TRUE)

# Data validation and understanding, including structure, content, and statistical characteristics covered below
```


### Explore & Visualize Series

```{r, class.output="output_small"}
# e.g., statistical characteristics (including distribution, skewness, outliers)
#   +[optionally] review sample observations
univariate(sales_df); head(sales_df, 3); #str(sales_df)
univariate(sales_test_df); head(sales_test_df, 3); #str(sales_test_df)
univariate(stores_df); head(stores_df, 3); #str(stores_df)
univariate(oil_df); head(oil_df, 3); #str(oil_df)
univariate(events_df); head(events_df, 3); #str(events_df)
```

```{r}
# Convert string mm/dd/yyyy to Date values and confirm sort
sales_df <- (sales_df %>%
               mutate(date = as.Date(date, format = "%Y-%m-%d"),) %>%
               arrange(date))
```

```{r}
# Aggregate base dataframe from daily to weekly for all product families
sales_wk_df <- as.data.frame(sales_df %>%
                               mutate(year = year(date), week = week(date)) %>%
                               group_by(year, week) %>%
                               summarize(sales = sum(sales / 1000.0)))

# Create overall time series
sales_begin_year <- head(sales_wk_df$year, 1)
sales_begin_week <- head(sales_wk_df$week, 1)
sales_end_year <- tail(sales_wk_df$year, 1)
sales_end_week <- tail(sales_wk_df$week, 1)
sales_ts <- ts(sales_wk_df$sales,
               start = c(sales_begin_year, sales_begin_week),
               end = c(sales_end_year, sales_end_week), freq = 52)

# Plot overall time series with trend line
plot(sales_ts, type = "l",
     main = "Store Sales for All Product Families | All Dates",
     xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
     las = 1, cex.axis = 0.7)

sales_lm <- tslm(sales_ts ~ trend + I(trend^2))
lines(sales_lm$fitted, lwd = 2, lty = 1, col = "orange")

# Plot overall time series w/log scale
plot(sales_ts, type = "l",
     main = "Store Sales for All Product Families | All Dates | Log Scale",
     xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
     las = 1, cex.axis = 0.7,
     log = "y")

# Plot zoomed time series with trend line
sales_zoom_ts <- window(sales_ts, start = c(sales_end_year, 1), end = c(sales_end_year, 13))
plot(sales_zoom_ts, type = "l",
     main = "Store Sales for All Product Families | One Quarter",
     xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
     xaxt = "n",
     las = 1, cex = 0.7)

sales_zoom_lm <- tslm(sales_zoom_ts ~ trend + I(trend^2))
lines(sales_zoom_lm$fitted, lwd = 2, lty = 1, col = "orange")

axis(1, at = as.numeric(time(sales_zoom_ts)), labels = seq(sales_zoom_ts))
```

```{r}
# Aggregate base dataframe from daily to weekly by product family
sales_wk_df <- as.data.frame(sales_df %>%
                               mutate(year = year(date), week = week(date)) %>%
                               group_by(family, year, week) %>%
                               summarize(sales = sum(sales / 1000.0)))

opar = par()
par(mfrow = c(1, 3))

for (f in unique(sales_wk_df$family)) {
  # Subset data by product family and create time series
  df <- filter(sales_wk_df, family == f)
  df_ts <- ts(df$sales,
              start = c(sales_begin_year, sales_begin_week),
              end = c(sales_end_year, sales_end_week), freq = 52)

  # Plot time series
  plot(df_ts, type = "l",
       main = paste("Store Sales for ", f, " | All Dates", sep = ""),
       xlab = TeX(r"(\textbf{Date (weekly \textit{$t$})} )"), ylab = TeX(r"(\textbf{Sales (\textit{$y_t$})} (000) )"),
       las = 1, cex.axis = 0.7)
}

par(opar)
```


### Pre-Process Data


### Partition Series

```{r}
# Use one year (52 weeks) as validation period (representative set of quarters, seasons)
sales_n_valid <- 52
sales_n_train <- length(sales_ts) - sales_n_valid

# Split data into training and validation periods
sales_train_ts <- window(sales_ts, start = c(sales_begin_year, 1), end = c(sales_begin_year, sales_n_train))
sales_valid_ts <- window(sales_ts, start = c(sales_begin_year, sales_n_train + 1), end = c(sales_begin_year, sales_n_train + sales_n_valid))
```


### Apply Forecasting Method(s)


### Evaluate & Compare Performance


### Implement Forecasts/System
